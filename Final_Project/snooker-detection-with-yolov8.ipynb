{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2315569,"sourceType":"datasetVersion","datasetId":1397425}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preparation","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import Video","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:46:12.633412Z","iopub.execute_input":"2023-12-29T15:46:12.633841Z","iopub.status.idle":"2023-12-29T15:46:12.943771Z","shell.execute_reply.started":"2023-12-29T15:46:12.633797Z","shell.execute_reply":"2023-12-29T15:46:12.942075Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"DATASET_PATH = \"/kaggle/input/snooker-balls/balls\"\nOUTPUT_PATH = \"/kaggle/working\"","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:46:12.946237Z","iopub.execute_input":"2023-12-29T15:46:12.946635Z","iopub.status.idle":"2023-12-29T15:46:12.954334Z","shell.execute_reply.started":"2023-12-29T15:46:12.946599Z","shell.execute_reply":"2023-12-29T15:46:12.952739Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Dataset ","metadata":{}},{"cell_type":"markdown","source":"### Original Dataset Structure\nDataset structure is given in next format:\n```\nsnooker-balls/balls/\n    train/\n        {class1}/\n            {id_1}.jpg\n            {id_2}.jpg\n            ...\n        {class2}/\n            ...\n        ...\n    test/\n    ...\n```","metadata":{}},{"cell_type":"markdown","source":"### Yolo Dataset Structure\nDataset structure should be transformed to next format:\n```\nyolo_dataset/\n    images/\n        train/\n            {class1}_{id_1}.jpg\n            {class1}_{id_2}.jpg\n            ...\n        val/\n            ...\n    labels/\n        train/\n            {class1}_{id_1}.txt\n            {class1}_{id_2}.txt\n            ...\n        val/\n            ...\n```","metadata":{}},{"cell_type":"code","source":"# root directory to save dataset in yolo format\nroot_dir=os.path.join(OUTPUT_PATH,\"yolo_dataset\")\nos.makedirs(root_dir, exist_ok=True)\n\n# train and test subdirectories with image directory\nimages_dir=os.path.join(root_dir,\"images\")\nos.makedirs(images_dir, exist_ok=True)\nos.makedirs(images_dir+\"/train\", exist_ok=True)\nos.makedirs(images_dir+\"/val\", exist_ok=True)\n\n# train and test subdirectories with label directory\nlabels_dir=os.path.join(root_dir,\"labels\")\nos.makedirs(labels_dir, exist_ok=True)\nos.makedirs(labels_dir+\"/train\", exist_ok=True)\nos.makedirs(labels_dir+\"/val\", exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:46:12.955666Z","iopub.execute_input":"2023-12-29T15:46:12.956054Z","iopub.status.idle":"2023-12-29T15:46:12.967814Z","shell.execute_reply.started":"2023-12-29T15:46:12.956023Z","shell.execute_reply":"2023-12-29T15:46:12.966463Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# variables to convert label/id to id/label\nlabel2id = {\"black\": 0, \"blue\": 1, \"brown\": 2, \"green\": 3, \"pink\": 4, \"red\": 5, \"white\": 6, \"yellow\": 7}\nid2label = {v: k for k, v in label2id.items()}","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:46:12.971157Z","iopub.execute_input":"2023-12-29T15:46:12.971650Z","iopub.status.idle":"2023-12-29T15:46:12.979452Z","shell.execute_reply.started":"2023-12-29T15:46:12.971605Z","shell.execute_reply":"2023-12-29T15:46:12.977835Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"for layer1 in os.listdir(DATASET_PATH):\n    for layer2 in os.listdir(f'{DATASET_PATH}/{layer1}'):\n        for layer3 in os.listdir(f'{DATASET_PATH}/{layer1}/{layer2}'):\n            if layer3.endswith('.jpg'):\n                shutil.copyfile(f'{DATASET_PATH}/{layer1}/{layer2}/{layer3}',f'{images_dir}/{layer1}/{layer2}_{layer3}'.replace('test', 'val' ))\n                f = open(f'{labels_dir}/{layer1}/{layer2}_{layer3}'[:-4].replace('test', 'val' )+'.txt', 'w')\n                f.write(str(label2id[layer2])+' 0.5 0.5 1 1')\n                f.close()","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:46:12.982047Z","iopub.execute_input":"2023-12-29T15:46:12.982939Z","iopub.status.idle":"2023-12-29T15:48:12.488256Z","shell.execute_reply.started":"2023-12-29T15:46:12.982878Z","shell.execute_reply":"2023-12-29T15:48:12.486853Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# YOLOv8","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics\n!yolo checks\nfrom ultralytics import YOLO","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:48:12.490215Z","iopub.execute_input":"2023-12-29T15:48:12.490683Z","iopub.status.idle":"2023-12-29T15:48:47.377572Z","shell.execute_reply.started":"2023-12-29T15:48:12.490640Z","shell.execute_reply":"2023-12-29T15:48:47.376377Z"},"scrolled":true,"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Obtaining dependency information for ultralytics from https://files.pythonhosted.org/packages/98/44/71231f2da4fb4a602d0cef2071adb708199e571ef89ed4a136f59c19d733/ultralytics-8.0.231-py3-none-any.whl.metadata\n  Downloading ultralytics-8.0.231-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.4)\nRequirement already satisfied: numpy>=1.22.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.24.3)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.8.1.78)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (10.1.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.31.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.0.0+cpu)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.15.1+cpu)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nCollecting thop>=0.1.1 (from ultralytics)\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.0.3)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.0.231-py3-none-any.whl (663 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.2/663.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: thop, ultralytics\nSuccessfully installed thop-0.1.1.post2209072238 ultralytics-8.0.231\nUltralytics YOLOv8.0.231 🚀 Python-3.10.12 torch-2.0.0+cpu CPU (Intel Xeon 2.20GHz)\nSetup complete ✅ (4 CPUs, 31.4 GB RAM, 5310.5/8062.4 GB disk)\n\nOS                  Linux-5.15.133+-x86_64-with-glibc2.31\nEnvironment         Kaggle\nPython              3.10.12\nInstall             pip\nRAM                 31.36 GB\nCPU                 Intel Xeon 2.20GHz\nCUDA                None\n\nmatplotlib          ✅ 3.7.4>=3.3.0\nnumpy               ✅ 1.24.3>=1.22.2\nopencv-python       ✅ 4.8.1.78>=4.6.0\npillow              ✅ 9.5.0>=7.1.2\npyyaml              ✅ 6.0.1>=5.3.1\nrequests            ✅ 2.31.0>=2.23.0\nscipy               ✅ 1.11.4>=1.4.1\ntorch               ✅ 2.0.0+cpu>=1.8.0\ntorchvision         ✅ 0.15.1+cpu>=0.9.0\ntqdm                ✅ 4.66.1>=4.64.0\npsutil              ✅ 5.9.5\npy-cpuinfo          ✅ 9.0.0\nthop                ✅ 0.1.1-2209072238>=0.1.1\npandas              ✅ 2.0.3>=1.1.4\nseaborn             ✅ 0.12.2>=0.11.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Convert Dataset to Yolo Format","metadata":{}},{"cell_type":"code","source":"names_content = \"\\n\".join([f\"  {label_id}: {label}\" for label, label_id in label2id.items()])\ndataset_content = f\"\"\"\npath: \"{root_dir}/\"\ntrain: \"images/train\"\nval: \"images/val\"\nnames:\n{names_content}\n\"\"\"\nwith open(os.path.join(OUTPUT_PATH, \"custom_dataset.yaml\"), \"w\") as f:\n    f.write(dataset_content)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:48:47.379278Z","iopub.execute_input":"2023-12-29T15:48:47.379738Z","iopub.status.idle":"2023-12-29T15:48:47.390346Z","shell.execute_reply.started":"2023-12-29T15:48:47.379705Z","shell.execute_reply":"2023-12-29T15:48:47.389232Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Train the Model","metadata":{}},{"cell_type":"code","source":"# pretrained model: yolov8n、yolov8s、yolov8m、yolov8l、yolov8x\nmodel = YOLO('yolov8n.yaml').load('yolov8n.pt')\n\n# Train the model using the processed dataset\nresults = model.train(\n    data=os.path.join(OUTPUT_PATH,'custom_dataset.yaml'),\n    project='snooker_project',\n    exist_ok=True,\n    epochs=10,\n    batch=8,\n    imgsz=8\n)\n#, optimizer='Adam', lr0=0.001, lrf=0.0005","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:16:07.435058Z","iopub.execute_input":"2023-12-29T16:16:07.435517Z","iopub.status.idle":"2023-12-29T16:47:33.909865Z","shell.execute_reply.started":"2023-12-29T16:16:07.435482Z","shell.execute_reply":"2023-12-29T16:47:33.908821Z"},"scrolled":true,"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \nYOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n\nTransferred 355/355 items from pretrained weights\nUltralytics YOLOv8.0.231 🚀 Python-3.10.12 torch-2.0.0+cpu CPU (Intel Xeon 2.20GHz)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/kaggle/working/custom_dataset.yaml, epochs=10, time=None, patience=50, batch=8, imgsz=8, save=True, save_period=-1, cache=False, device=None, workers=8, project=snooker_project, name=train, exist_ok=True, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.0005, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=snooker_project/train\nOverriding model.yaml nc=80 with nc=8\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    752872  ultralytics.nn.modules.head.Detect           [8, [64, 128, 256]]           \nYOLOv8n summary: 225 layers, 3012408 parameters, 3012392 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir snooker_project/train', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\nWARNING ⚠️ imgsz=[8] must be multiple of max stride 32, updating to [32]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolo_dataset/labels/train.cache... 11510 images, 0 backgrounds, 0 corrupt: 100%|██████████| 11510/11510 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolo_dataset/labels/val.cache... 2873 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2873/2873 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Plotting labels to snooker_project/train/labels.jpg... \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nWARNING ⚠️ TensorBoard graph visualization failure Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])\n10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/10         0G      0.386     0.9123     0.9843          6         32: 100%|██████████| 1439/1439 [02:55<00:00,  8.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 180/180 [00:15<00:00, 11.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.865       0.58      0.822      0.732\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/10         0G     0.2494     0.4459     0.9471          6         32: 100%|██████████| 1439/1439 [02:39<00:00,  9.01it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 180/180 [00:16<00:00, 11.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873       0.75       0.93      0.981      0.894\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/10         0G     0.2083     0.3413     0.9355          6         32: 100%|██████████| 1439/1439 [02:50<00:00,  8.44it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 180/180 [00:15<00:00, 11.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.865      0.968      0.984      0.906\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/10         0G     0.1948     0.2872     0.9315          6         32: 100%|██████████| 1439/1439 [02:59<00:00,  8.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 180/180 [00:15<00:00, 11.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.795      0.906      0.966      0.828\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/10         0G     0.1837     0.2662     0.9292          6         32: 100%|██████████| 1439/1439 [02:39<00:00,  9.02it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 180/180 [00:15<00:00, 11.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.656      0.891      0.938      0.794\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/10         0G     0.1782     0.2459     0.9254          6         32: 100%|██████████| 1439/1439 [02:33<00:00,  9.38it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 180/180 [00:15<00:00, 11.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.647      0.913      0.893      0.684\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/10         0G     0.1671     0.2259     0.9238          6         32: 100%|██████████| 1439/1439 [02:36<00:00,  9.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 180/180 [00:15<00:00, 11.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.717      0.908      0.921      0.776\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       8/10         0G     0.1585     0.2037     0.9215          6         32: 100%|██████████| 1439/1439 [02:40<00:00,  8.97it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 180/180 [00:15<00:00, 11.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.665      0.935      0.912      0.709\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/10         0G     0.1543     0.1909     0.9182          6         32: 100%|██████████| 1439/1439 [02:38<00:00,  9.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 180/180 [00:17<00:00, 10.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.746      0.945      0.936      0.771\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/10         0G     0.1456     0.1776     0.9205          6         32: 100%|██████████| 1439/1439 [02:42<00:00,  8.86it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 180/180 [00:37<00:00,  4.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.753      0.943       0.96      0.758\n\n10 epochs completed in 0.509 hours.\nOptimizer stripped from snooker_project/train/weights/last.pt, 6.2MB\nOptimizer stripped from snooker_project/train/weights/best.pt, 6.2MB\n\nValidating snooker_project/train/weights/best.pt...\nUltralytics YOLOv8.0.231 🚀 Python-3.10.12 torch-2.0.0+cpu CPU (Intel Xeon 2.20GHz)\nYOLOv8n summary (fused): 168 layers, 3007208 parameters, 0 gradients, 8.1 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 180/180 [00:15<00:00, 11.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.865      0.968      0.984      0.906\n                 black       2873        359      0.988      0.983      0.985      0.895\n                  blue       2873        323      0.979          1       0.98      0.838\n                 brown       2873        331      0.791      0.976      0.963      0.837\n                 green       2873        239      0.975          1      0.995      0.985\n                  pink       2873         42      0.251          1      0.993      0.993\n                   red       2873        322      0.977      0.786      0.964       0.86\n                 white       2873       1233      0.964      0.997      0.995      0.945\n                yellow       2873         24      0.994          1      0.995      0.895\nSpeed: 0.0ms preprocess, 2.2ms inference, 0.0ms loss, 0.5ms postprocess per image\nResults saved to \u001b[1msnooker_project/train\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='7.904 MB of 7.904 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>▂▅█▇▇▆▄▄▂▁</td></tr><tr><td>lr/pg1</td><td>▂▅█▇▇▆▄▄▂▁</td></tr><tr><td>lr/pg2</td><td>▂▅█▇▇▆▄▄▂▁</td></tr><tr><td>metrics/mAP50(B)</td><td>▁▆▅▄▂▃▃▆▇█</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▁▇▆▄▂▄▃▃▄█</td></tr><tr><td>metrics/precision(B)</td><td>▅▄▄▃▁▁▃▄▆█</td></tr><tr><td>metrics/recall(B)</td><td>▁▆▆▄▂▇▅▇██</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>█▃▂▂▂▂▁▁▁▁</td></tr><tr><td>train/cls_loss</td><td>█▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train/dfl_loss</td><td>█▃▃▃▃▂▂▁▁▁</td></tr><tr><td>val/box_loss</td><td>▂▁▂▃▂▃▃█▇█</td></tr><tr><td>val/cls_loss</td><td>▃▁▃▂▄█▃▄▃█</td></tr><tr><td>val/dfl_loss</td><td>▃▁▂▂▁▁▁█▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0002</td></tr><tr><td>lr/pg1</td><td>0.0002</td></tr><tr><td>lr/pg2</td><td>0.0002</td></tr><tr><td>metrics/mAP50(B)</td><td>0.98393</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.90614</td></tr><tr><td>metrics/precision(B)</td><td>0.86481</td></tr><tr><td>metrics/recall(B)</td><td>0.96779</td></tr><tr><td>model/GFLOPs</td><td>8.202</td></tr><tr><td>model/parameters</td><td>3012408</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>2.498</td></tr><tr><td>train/box_loss</td><td>0.14558</td></tr><tr><td>train/cls_loss</td><td>0.17763</td></tr><tr><td>train/dfl_loss</td><td>0.92048</td></tr><tr><td>val/box_loss</td><td>0.97564</td></tr><tr><td>val/cls_loss</td><td>3.18519</td></tr><tr><td>val/dfl_loss</td><td>1.09253</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">train</strong> at: <a href='https://wandb.ai/yustinachang/snooker_project/runs/83n1m6sj' target=\"_blank\">https://wandb.ai/yustinachang/snooker_project/runs/83n1m6sj</a><br/>Synced 6 W&B file(s), 25 media file(s), 5 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20231229_154957-83n1m6sj/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 1 is less than current step: 8. Dropping entry: {'train/box_loss': 0.38605, 'train/cls_loss': 0.91226, 'train/dfl_loss': 0.98427, '_timestamp': 1703866753.008067})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 1 is less than current step: 8. Dropping entry: {'lr/pg0': 0.06702293259207784, 'lr/pg1': 0.0003331016909891128, 'lr/pg2': 0.0003331016909891128, '_timestamp': 1703866753.0089066})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 1 is less than current step: 8. Dropping entry: {'metrics/precision(B)': 0.8646, 'metrics/recall(B)': 0.58046, 'metrics/mAP50(B)': 0.82153, 'metrics/mAP50-95(B)': 0.73231, 'val/box_loss': 0.72723, 'val/cls_loss': 1.44524, 'val/dfl_loss': 1.06831, '_timestamp': 1703866771.2382703})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 1 is less than current step: 8. Dropping entry: {'labels': {'_type': 'image-file', 'sha256': 'c440250b6d431c8e015c78cd524bf58c0080bf2be8f93367d934761a4fbad55d', 'size': 82122, 'path': 'media/images/labels_8_c440250b6d431c8e015c.jpg', 'format': 'jpg', 'width': 1600, 'height': 1600}, '_timestamp': 1703866771.2581286})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 1 is less than current step: 8. Dropping entry: {'train_batch0': {'_type': 'image-file', 'sha256': 'ba3fb4cbcf53c86195120dcd216d20e65c1416d06964e272d9499508fc2ace1f', 'size': 3158, 'path': 'media/images/train_batch0_8_ba3fb4cbcf53c8619512.jpg', 'format': 'jpg', 'width': 96, 'height': 96}, '_timestamp': 1703866771.2681296})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 1 is less than current step: 8. Dropping entry: {'train_batch1': {'_type': 'image-file', 'sha256': '3dc9070f2a6711d8423c5bdd8cde8d2b2fb33c87b94ac1e361ba57919c787840', 'size': 3389, 'path': 'media/images/train_batch1_8_3dc9070f2a6711d8423c.jpg', 'format': 'jpg', 'width': 96, 'height': 96}, '_timestamp': 1703866771.2766025})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 1 is less than current step: 8. Dropping entry: {'train_batch2': {'_type': 'image-file', 'sha256': 'abc1cc0238d7ecd7e02083850f17e562a4e697dad00f4bd56a48c450ad9703c9', 'size': 3353, 'path': 'media/images/train_batch2_8_abc1cc0238d7ecd7e020.jpg', 'format': 'jpg', 'width': 96, 'height': 96}, '_timestamp': 1703866771.2875125})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 1 is less than current step: 8. Dropping entry: {'model/parameters': 3012408, 'model/GFLOPs': 8.202, 'model/speed_PyTorch(ms)': 2.497, '_timestamp': 1703866771.4024415})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 2 is less than current step: 8. Dropping entry: {'train/box_loss': 0.24936, 'train/cls_loss': 0.44591, 'train/dfl_loss': 0.9471, '_timestamp': 1703866931.1394012})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 2 is less than current step: 8. Dropping entry: {'lr/pg0': 0.0339563224113968, 'lr/pg1': 0.0005998248436414177, 'lr/pg2': 0.0005998248436414177, '_timestamp': 1703866931.1398578})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 2 is less than current step: 8. Dropping entry: {'metrics/precision(B)': 0.74979, 'metrics/recall(B)': 0.92959, 'metrics/mAP50(B)': 0.98131, 'metrics/mAP50-95(B)': 0.89434, 'val/box_loss': 0.57009, 'val/cls_loss': 1.38258, 'val/dfl_loss': 1.05322, '_timestamp': 1703866949.4928656})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 3 is less than current step: 8. Dropping entry: {'train/box_loss': 0.20831, 'train/cls_loss': 0.34129, 'train/dfl_loss': 0.9355, '_timestamp': 1703867120.0702548})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 3 is less than current step: 8. Dropping entry: {'lr/pg0': 0.0008230788973824371, 'lr/pg1': 0.0007999146629603893, 'lr/pg2': 0.0007999146629603893, '_timestamp': 1703867120.0711405})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 3 is less than current step: 8. Dropping entry: {'metrics/precision(B)': 0.86476, 'metrics/recall(B)': 0.96756, 'metrics/mAP50(B)': 0.98394, 'metrics/mAP50-95(B)': 0.90615, 'val/box_loss': 0.63437, 'val/cls_loss': 1.33768, 'val/dfl_loss': 1.05295, '_timestamp': 1703867137.477281})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 4 is less than current step: 8. Dropping entry: {'train/box_loss': 0.19484, 'train/cls_loss': 0.28721, 'train/dfl_loss': 0.93154, '_timestamp': 1703867316.5206244})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 4 is less than current step: 8. Dropping entry: {'lr/pg0': 0.00070015, 'lr/pg1': 0.00070015, 'lr/pg2': 0.00070015, '_timestamp': 1703867316.520936})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 4 is less than current step: 8. Dropping entry: {'metrics/precision(B)': 0.79469, 'metrics/recall(B)': 0.90589, 'metrics/mAP50(B)': 0.96649, 'metrics/mAP50-95(B)': 0.8279, 'val/box_loss': 0.85177, 'val/cls_loss': 1.96719, 'val/dfl_loss': 1.08389, '_timestamp': 1703867333.3380852})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 5 is less than current step: 8. Dropping entry: {'train/box_loss': 0.1837, 'train/cls_loss': 0.26623, 'train/dfl_loss': 0.92917, '_timestamp': 1703867492.8322105})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 5 is less than current step: 8. Dropping entry: {'lr/pg0': 0.00070015, 'lr/pg1': 0.00070015, 'lr/pg2': 0.00070015, '_timestamp': 1703867492.8327963})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 5 is less than current step: 8. Dropping entry: {'metrics/precision(B)': 0.65641, 'metrics/recall(B)': 0.89074, 'metrics/mAP50(B)': 0.93849, 'metrics/mAP50-95(B)': 0.79392, 'val/box_loss': 0.88196, 'val/cls_loss': 2.45196, 'val/dfl_loss': 1.08498, '_timestamp': 1703867509.3681448})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 6 is less than current step: 8. Dropping entry: {'train/box_loss': 0.17818, 'train/cls_loss': 0.24589, 'train/dfl_loss': 0.92544, '_timestamp': 1703867662.857149})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 6 is less than current step: 8. Dropping entry: {'lr/pg0': 0.0006002, 'lr/pg1': 0.0006002, 'lr/pg2': 0.0006002, '_timestamp': 1703867662.8574774})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 6 is less than current step: 8. Dropping entry: {'metrics/precision(B)': 0.64709, 'metrics/recall(B)': 0.91276, 'metrics/mAP50(B)': 0.89304, 'metrics/mAP50-95(B)': 0.6841, 'val/box_loss': 0.90092, 'val/cls_loss': 2.34529, 'val/dfl_loss': 1.08789, '_timestamp': 1703867680.6934533})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 7 is less than current step: 8. Dropping entry: {'train/box_loss': 0.16706, 'train/cls_loss': 0.22592, 'train/dfl_loss': 0.92376, '_timestamp': 1703867837.2480311})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 7 is less than current step: 8. Dropping entry: {'lr/pg0': 0.0005002499999999999, 'lr/pg1': 0.0005002499999999999, 'lr/pg2': 0.0005002499999999999, '_timestamp': 1703867837.248479})."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"(User provided step: 7 is less than current step: 8. Dropping entry: {'metrics/precision(B)': 0.71706, 'metrics/recall(B)': 0.90838, 'metrics/mAP50(B)': 0.92118, 'metrics/mAP50-95(B)': 0.7764, 'val/box_loss': 0.85026, 'val/cls_loss': 3.6773, 'val/dfl_loss': 1.08114, '_timestamp': 1703867853.8468087})."},"metadata":{}}]},{"cell_type":"markdown","source":"### Validate the Model","metadata":{}},{"cell_type":"code","source":"metrics = model.val()  # no arguments needed, dataset and settings remembered\nmetrics.box.map    # map50-95\nmetrics.box.map50  # map50\nmetrics.box.map75  # map75\nmetrics.box.maps   # a list contains map50-95 of each category","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:49:41.707097Z","iopub.status.idle":"2023-12-29T15:49:41.707517Z","shell.execute_reply.started":"2023-12-29T15:49:41.707322Z","shell.execute_reply":"2023-12-29T15:49:41.707341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Export the Model with **ONNX**","metadata":{"_kg_hide-input":false}},{"cell_type":"code","source":"model.export(format='onnx')","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-12-29T15:49:41.708865Z","iopub.status.idle":"2023-12-29T15:49:41.709359Z","shell.execute_reply.started":"2023-12-29T15:49:41.709163Z","shell.execute_reply":"2023-12-29T15:49:41.709183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Benchmark the Model with **ONNX**","metadata":{"_kg_hide-input":false}},{"cell_type":"code","source":"from ultralytics.utils.benchmarks import benchmark\nbenchmark(model='snooker_project/train2/weights/best.pt', imgsz=128)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-12-29T15:49:41.712153Z","iopub.status.idle":"2023-12-29T15:49:41.713526Z","shell.execute_reply.started":"2023-12-29T15:49:41.713204Z","shell.execute_reply":"2023-12-29T15:49:41.713237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create a Download Link","metadata":{}},{"cell_type":"code","source":"%cd $OUTPUT_PATH\n!zip -r snooker_project.zip snooker_project\nfrom IPython.display import FileLink\nFileLink(r'snooker_project.zip')","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:49:41.715425Z","iopub.status.idle":"2023-12-29T15:49:41.716436Z","shell.execute_reply.started":"2023-12-29T15:49:41.716114Z","shell.execute_reply":"2023-12-29T15:49:41.716144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Video with PyTube","metadata":{}},{"cell_type":"code","source":"!pip install pytube\nfrom pytube import YouTube\nYouTube('https://youtu.be/hw02UKK4Kb0').streams.filter().get_highest_resolution().download(output_path=OUTPUT_PATH, filename='youtube.mp4')","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:49:41.718674Z","iopub.status.idle":"2023-12-29T15:49:41.719335Z","shell.execute_reply.started":"2023-12-29T15:49:41.719002Z","shell.execute_reply":"2023-12-29T15:49:41.719041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd $OUTPUT_PATH\n!ffmpeg -i youtube.mp4 -vcodec copy -acodec copy -ss 00:01:05 -to 00:01:15 video.mp4 -y","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:49:41.720940Z","iopub.status.idle":"2023-12-29T15:49:41.722222Z","shell.execute_reply.started":"2023-12-29T15:49:41.721600Z","shell.execute_reply":"2023-12-29T15:49:41.721644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd $OUTPUT_PATH\nVideo('video.mp4', width=840)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:49:41.724450Z","iopub.status.idle":"2023-12-29T15:49:41.725084Z","shell.execute_reply.started":"2023-12-29T15:49:41.724785Z","shell.execute_reply":"2023-12-29T15:49:41.724815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict the Video","metadata":{}},{"cell_type":"code","source":"%cd $OUTPUT_PATH\nvideo_model = YOLO(\"snooker_project/train/weights/best.pt\")\nvideo_model.predict(source=\"video.mp4\", show=False, save=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:49:41.726977Z","iopub.status.idle":"2023-12-29T15:49:41.727443Z","shell.execute_reply.started":"2023-12-29T15:49:41.727224Z","shell.execute_reply":"2023-12-29T15:49:41.727245Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd $OUTPUT_PATH\n!ffmpeg -y -loglevel panic -i runs/detect/predict/video.avi predict_video.mp4\n# Display the video \nVideo(\"predict_video.mp4\", width=840)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:49:41.730171Z","iopub.status.idle":"2023-12-29T15:49:41.730796Z","shell.execute_reply.started":"2023-12-29T15:49:41.730434Z","shell.execute_reply":"2023-12-29T15:49:41.730456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Track the Video with **ByteTrack**","metadata":{}},{"cell_type":"code","source":"%cd $OUTPUT_PATH\nvidel_model = YOLO('snooker_project/train/weights/best.pt')\nvidel_model.track(source=\"video.mp4\", tracker=\"bytetrack.yaml\", save=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:49:41.734021Z","iopub.status.idle":"2023-12-29T15:49:41.734976Z","shell.execute_reply.started":"2023-12-29T15:49:41.734532Z","shell.execute_reply":"2023-12-29T15:49:41.734578Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd $OUTPUT_PATH\n!ffmpeg -y -loglevel panic -i runs/detect/predict2/video.avi track_video.mp4\n# Display the video \nVideo(\"track_video.mp4\", width=840)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:49:41.737838Z","iopub.status.idle":"2023-12-29T15:49:41.738471Z","shell.execute_reply.started":"2023-12-29T15:49:41.738175Z","shell.execute_reply":"2023-12-29T15:49:41.738205Z"},"trusted":true},"execution_count":null,"outputs":[]}]}