{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2315569,"sourceType":"datasetVersion","datasetId":1397425},{"sourceId":7308239,"sourceType":"datasetVersion","datasetId":4240434}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preparation","metadata":{"_kg_hide-output":false}},{"cell_type":"code","source":"import os\nimport cv2\nimport shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image, Video","metadata":{"execution":{"iopub.status.busy":"2024-04-08T23:31:14.457116Z","iopub.execute_input":"2024-04-08T23:31:14.457566Z","iopub.status.idle":"2024-04-08T23:31:14.745710Z","shell.execute_reply.started":"2024-04-08T23:31:14.457525Z","shell.execute_reply":"2024-04-08T23:31:14.744711Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"OUTPUT_PATH = \"/kaggle/working\"\nDATASET_PATH = \"/kaggle/input/snooker-balls/balls\"\ndataset_path = \"/kaggle/working/yolo_dataset\"","metadata":{"execution":{"iopub.status.busy":"2024-04-08T23:33:37.780135Z","iopub.execute_input":"2024-04-08T23:33:37.780663Z","iopub.status.idle":"2024-04-08T23:33:37.786919Z","shell.execute_reply.started":"2024-04-08T23:33:37.780618Z","shell.execute_reply":"2024-04-08T23:33:37.785556Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Dataset ","metadata":{}},{"cell_type":"markdown","source":"### Original Dataset Structure\nDataset structure is given in next format:\n```\nsnooker-balls/balls/\n    train/\n        {class1}/\n            {id_1}.jpg\n            {id_2}.jpg\n            ...\n        {class2}/\n            ...\n        ...\n    test/\n    ...\n```","metadata":{}},{"cell_type":"markdown","source":"### Yolo Dataset Structure\nDataset structure should be transformed to next format:\n```\nyolo_dataset/\n    images/\n        train/\n            {class1}_{id_1}.jpg\n            {class1}_{id_2}.jpg\n            ...\n        val/\n            ...\n    labels/\n        train/\n            {class1}_{id_1}.txt\n            {class1}_{id_2}.txt\n            ...\n        val/\n            ...\n```","metadata":{}},{"cell_type":"code","source":"# root directory to save dataset in yolo format\nos.makedirs(dataset_path, exist_ok=True)\n\nos.makedirs(f'{dataset_path}/images', exist_ok=True)\nos.makedirs(f'{dataset_path}/images/train', exist_ok=True)\nos.makedirs(f'{dataset_path}/images/val', exist_ok=True)\n\nos.makedirs(f'{dataset_path}/labels', exist_ok=True)\nos.makedirs(f'{dataset_path}/labels/train', exist_ok=True)\nos.makedirs(f'{dataset_path}/labels/val', exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T23:33:45.477364Z","iopub.execute_input":"2024-04-08T23:33:45.477773Z","iopub.status.idle":"2024-04-08T23:33:45.486983Z","shell.execute_reply.started":"2024-04-08T23:33:45.477742Z","shell.execute_reply":"2024-04-08T23:33:45.485091Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# variables to convert label/id to id/label\nlabel2id = {\"black\": 0, \"blue\": 1, \"brown\": 2, \"green\": 3, \"pink\": 4, \"red\": 5, \"white\": 6, \"yellow\": 7}\nid2label = {v: k for k, v in label2id.items()}","metadata":{"execution":{"iopub.status.busy":"2024-04-08T23:33:48.202531Z","iopub.execute_input":"2024-04-08T23:33:48.202909Z","iopub.status.idle":"2024-04-08T23:33:48.209766Z","shell.execute_reply.started":"2024-04-08T23:33:48.202880Z","shell.execute_reply":"2024-04-08T23:33:48.208388Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"for layer1 in os.listdir(DATASET_PATH):\n    for layer2 in os.listdir(f'{DATASET_PATH}/{layer1}'):\n        for layer3 in os.listdir(f'{DATASET_PATH}/{layer1}/{layer2}'):\n            if layer3.endswith('.jpg'):\n                shutil.copyfile(f'{DATASET_PATH}/{layer1}/{layer2}/{layer3}',f'{dataset_path}/images/{layer1}/{layer2}_{layer3}'.replace('test', 'val' ))\n                f = open(f'{dataset_path}/labels/{layer1}/{layer2}_{layer3}'.replace('test', 'val' ).replace('.jpg', '.txt' ), 'w')\n                f.write(f'{label2id[layer2]} 0.5 0.5 1 1')\n                f.close()","metadata":{"execution":{"iopub.status.busy":"2024-04-08T23:33:50.864428Z","iopub.execute_input":"2024-04-08T23:33:50.864856Z","iopub.status.idle":"2024-04-08T23:35:55.221001Z","shell.execute_reply.started":"2024-04-08T23:33:50.864823Z","shell.execute_reply":"2024-04-08T23:35:55.219569Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# YOLOv8","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics==8.0.231\n!yolo checks\nfrom ultralytics import YOLO","metadata":{"scrolled":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-04-08T23:37:25.466929Z","iopub.execute_input":"2024-04-08T23:37:25.467344Z","iopub.status.idle":"2024-04-08T23:37:57.817307Z","shell.execute_reply.started":"2024-04-08T23:37:25.467310Z","shell.execute_reply":"2024-04-08T23:37:57.816216Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting ultralytics==8.0.231\n  Obtaining dependency information for ultralytics==8.0.231 from https://files.pythonhosted.org/packages/98/44/71231f2da4fb4a602d0cef2071adb708199e571ef89ed4a136f59c19d733/ultralytics-8.0.231-py3-none-any.whl.metadata\n  Downloading ultralytics-8.0.231-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.231) (3.7.4)\nRequirement already satisfied: numpy>=1.22.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.231) (1.24.3)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.231) (4.8.1.78)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.231) (10.1.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.231) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.231) (2.31.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.231) (1.11.4)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.231) (2.0.0+cpu)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.231) (0.15.1+cpu)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.231) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.231) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.231) (9.0.0)\nCollecting thop>=0.1.1 (from ultralytics==8.0.231)\n  Obtaining dependency information for thop>=0.1.1 from https://files.pythonhosted.org/packages/bb/0f/72beeab4ff5221dc47127c80f8834b4bcd0cb36f6ba91c0b1d04a1233403/thop-0.1.1.post2209072238-py3-none-any.whl.metadata\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.231) (2.0.3)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.231) (0.12.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.0.231) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.0.231) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.0.231) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.0.231) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.0.231) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.0.231) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.0.231) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics==8.0.231) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics==8.0.231) (2023.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.0.231) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.0.231) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.0.231) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.0.231) (2023.11.17)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.231) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.231) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.231) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.231) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.231) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.0.231) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics==8.0.231) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics==8.0.231) (1.3.0)\nDownloading ultralytics-8.0.231-py3-none-any.whl (663 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.2/663.2 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nInstalling collected packages: thop, ultralytics\nSuccessfully installed thop-0.1.1.post2209072238 ultralytics-8.0.231\nUltralytics YOLOv8.0.231 🚀 Python-3.10.12 torch-2.0.0+cpu CPU (Intel Xeon 2.20GHz)\nSetup complete ✅ (4 CPUs, 31.4 GB RAM, 5563.1/8062.4 GB disk)\n\nOS                  Linux-5.15.133+-x86_64-with-glibc2.31\nEnvironment         Kaggle\nPython              3.10.12\nInstall             pip\nRAM                 31.36 GB\nCPU                 Intel Xeon 2.20GHz\nCUDA                None\n\nmatplotlib          ✅ 3.7.4>=3.3.0\nnumpy               ✅ 1.24.3>=1.22.2\nopencv-python       ✅ 4.8.1.78>=4.6.0\npillow              ✅ 9.5.0>=7.1.2\npyyaml              ✅ 6.0.1>=5.3.1\nrequests            ✅ 2.31.0>=2.23.0\nscipy               ✅ 1.11.4>=1.4.1\ntorch               ✅ 2.0.0+cpu>=1.8.0\ntorchvision         ✅ 0.15.1+cpu>=0.9.0\ntqdm                ✅ 4.66.1>=4.64.0\npsutil              ✅ 5.9.5\npy-cpuinfo          ✅ 9.0.0\nthop                ✅ 0.1.1-2209072238>=0.1.1\npandas              ✅ 2.0.3>=1.1.4\nseaborn             ✅ 0.12.2>=0.11.0\n","output_type":"stream"}]},{"cell_type":"code","source":"names_content = \"\\n\".join([f\"  {label_id}: {label}\" for label, label_id in label2id.items()])\ndataset_content = f\"\"\"\npath: \"{dataset_path}/\"\ntrain: \"images/train\"\nval: \"images/val\"\nnames:\n{names_content}\n\"\"\"\nwith open(os.path.join(OUTPUT_PATH, \"custom_dataset.yaml\"), \"w\") as f:\n    f.write(dataset_content)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T23:43:33.847498Z","iopub.execute_input":"2024-04-08T23:43:33.848139Z","iopub.status.idle":"2024-04-08T23:43:33.855836Z","shell.execute_reply.started":"2024-04-08T23:43:33.848101Z","shell.execute_reply":"2024-04-08T23:43:33.854680Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# pretrained model: yolov8n、yolov8s、yolov8m、yolov8l、yolov8x\nmodel = YOLO('yolov8n.yaml').load('yolov8n.pt')\n\n# Train the model using the processed dataset\nresults = model.train(\n    data=os.path.join(OUTPUT_PATH,'custom_dataset.yaml'),\n    project='snooker_project',\n    exist_ok=True,\n    epochs=20,\n    batch=64,\n    imgsz=32,\n    optimizer='Adam',\n    lr0=0.001,\n    lrf=0.0005\n)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-04-08T23:45:00.561018Z","iopub.execute_input":"2024-04-08T23:45:00.561579Z","iopub.status.idle":"2024-04-09T00:23:14.989779Z","shell.execute_reply.started":"2024-04-08T23:45:00.561532Z","shell.execute_reply":"2024-04-09T00:23:14.988550Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \nYOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n\nDownloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6.23M/6.23M [00:00<00:00, 137MB/s]","output_type":"stream"},{"name":"stdout","text":"Transferred 355/355 items from pretrained weights\nNew https://pypi.org/project/ultralytics/8.1.45 available 😃 Update with 'pip install -U ultralytics'\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Ultralytics YOLOv8.0.231 🚀 Python-3.10.12 torch-2.0.0+cpu CPU (Intel Xeon 2.20GHz)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/kaggle/working/custom_dataset.yaml, epochs=20, time=None, patience=50, batch=64, imgsz=32, save=True, save_period=-1, cache=False, device=None, workers=8, project=snooker_project, name=train, exist_ok=True, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.0005, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=snooker_project/train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 755k/755k [00:00<00:00, 39.8MB/s]\n2024-04-08 23:45:06,686\tINFO util.py:129 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-04-08 23:45:07,875\tINFO util.py:129 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=8\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    752872  ultralytics.nn.modules.head.Detect           [8, [64, 128, 256]]           \nYOLOv8n summary: 225 layers, 3012408 parameters, 3012392 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir snooker_project/train', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240408_234551-g87o60wf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/yustinachang/snooker_project/runs/g87o60wf' target=\"_blank\">train</a></strong> to <a href='https://wandb.ai/yustinachang/snooker_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/yustinachang/snooker_project' target=\"_blank\">https://wandb.ai/yustinachang/snooker_project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/yustinachang/snooker_project/runs/g87o60wf' target=\"_blank\">https://wandb.ai/yustinachang/snooker_project/runs/g87o60wf</a>"},"metadata":{}},{"name":"stdout","text":"Freezing layer 'model.22.dfl.conv.weight'\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolo_dataset/labels/train... 11510 images, 0 backgrounds, 0 corrupt: 100%|██████████| 11510/11510 [00:09<00:00, 1217.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolo_dataset/labels/train.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolo_dataset/labels/val... 2873 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2873/2873 [00:02<00:00, 1206.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/yolo_dataset/labels/val.cache\nPlotting labels to snooker_project/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nWARNING ⚠️ TensorBoard graph visualization failure Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])\n20 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/20         0G     0.8674      1.603      1.033        165         32: 100%|██████████| 180/180 [01:20<00:00,  2.23it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:11<00:00,  1.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.649      0.692      0.623      0.563\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/20         0G     0.5496      0.805     0.9631        161         32: 100%|██████████| 180/180 [01:15<00:00,  2.38it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:11<00:00,  2.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.635       0.79      0.757      0.604\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/20         0G     0.4913     0.6356     0.9406        164         32: 100%|██████████| 180/180 [01:18<00:00,  2.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:11<00:00,  2.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.537      0.782      0.806      0.666\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/20         0G       0.45     0.5559     0.9274        166         32: 100%|██████████| 180/180 [01:19<00:00,  2.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:10<00:00,  2.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.701      0.752      0.965      0.897\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/20         0G     0.4104     0.5089     0.9216        162         32: 100%|██████████| 180/180 [01:31<00:00,  1.98it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:10<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.628      0.742      0.931      0.896\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/20         0G     0.3776     0.4654     0.9185        165         32: 100%|██████████| 180/180 [01:53<00:00,  1.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:10<00:00,  2.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.911      0.801      0.959      0.885\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/20         0G     0.3633     0.4489     0.9118        174         32: 100%|██████████| 180/180 [01:44<00:00,  1.72it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:10<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.889      0.942      0.978      0.922\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       8/20         0G     0.3486     0.4135     0.9103        176         32: 100%|██████████| 180/180 [01:32<00:00,  1.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:10<00:00,  2.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.879      0.924      0.941      0.856\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/20         0G      0.336     0.4021     0.9096        153         32: 100%|██████████| 180/180 [01:31<00:00,  1.97it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:10<00:00,  2.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.908      0.937      0.971      0.936\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/20         0G     0.3306     0.3931     0.9101        175         32: 100%|██████████| 180/180 [01:30<00:00,  1.98it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:10<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873       0.96      0.968      0.985      0.955\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      11/20         0G     0.2277     0.3083     0.9282         54         32: 100%|██████████| 180/180 [01:11<00:00,  2.50it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:10<00:00,  2.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.943      0.954      0.977       0.86\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      12/20         0G      0.188      0.226     0.9147         54         32: 100%|██████████| 180/180 [01:12<00:00,  2.48it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:10<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.983      0.988      0.991      0.856\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      13/20         0G     0.1759       0.21     0.9116         54         32: 100%|██████████| 180/180 [01:14<00:00,  2.43it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:10<00:00,  2.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873       0.87      0.928      0.983      0.799\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      14/20         0G     0.1618     0.1846     0.9122         54         32: 100%|██████████| 180/180 [01:15<00:00,  2.37it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:34<00:00,  1.52s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.975      0.977       0.99      0.802\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      15/20         0G     0.1585     0.1699     0.9068         54         32: 100%|██████████| 180/180 [01:25<00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:41<00:00,  1.82s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.856      0.972      0.975      0.841\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      16/20         0G     0.1576     0.1691     0.9032         54         32: 100%|██████████| 180/180 [01:23<00:00,  2.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:41<00:00,  1.81s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.925      0.942      0.988      0.819\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      17/20         0G     0.1506     0.1583     0.9049         54         32: 100%|██████████| 180/180 [01:23<00:00,  2.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:41<00:00,  1.83s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.935      0.986      0.978      0.747\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      18/20         0G     0.1444     0.1488     0.9036         54         32: 100%|██████████| 180/180 [01:22<00:00,  2.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:41<00:00,  1.82s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.896      0.967      0.991      0.801\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      19/20         0G     0.1366     0.1399     0.9038         54         32: 100%|██████████| 180/180 [01:22<00:00,  2.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:41<00:00,  1.82s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.921      0.941       0.99      0.824\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      20/20         0G     0.1319      0.131     0.9078         54         32: 100%|██████████| 180/180 [01:22<00:00,  2.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:41<00:00,  1.81s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873      0.863      0.941      0.985      0.786\n\n20 epochs completed in 0.597 hours.\nOptimizer stripped from snooker_project/train/weights/last.pt, 6.2MB\nOptimizer stripped from snooker_project/train/weights/best.pt, 6.2MB\n\nValidating snooker_project/train/weights/best.pt...\nUltralytics YOLOv8.0.231 🚀 Python-3.10.12 torch-2.0.0+cpu CPU (Intel Xeon 2.20GHz)\nYOLOv8n summary (fused): 168 layers, 3007208 parameters, 0 gradients, 8.1 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:15<00:00,  1.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873       0.96      0.967      0.985      0.955\n                 black       2873        359      0.974      0.932      0.981      0.971\n                  blue       2873        323      0.982          1       0.98      0.883\n                 brown       2873        331      0.876        0.9      0.972       0.96\n                 green       2873        239       0.98          1      0.995      0.993\n                  pink       2873         42      0.994          1      0.995      0.989\n                   red       2873        322      0.896      0.909      0.968      0.873\n                 white       2873       1233      0.997      0.997      0.995      0.972\n                yellow       2873         24      0.983          1      0.995      0.995\nSpeed: 0.0ms preprocess, 1.3ms inference, 0.0ms loss, 0.5ms postprocess per image\nResults saved to \u001b[1msnooker_project/train\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='7.751 MB of 7.771 MB uploaded\\r'), FloatProgress(value=0.9974163568225755, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr/pg1</td><td>▃▆███▇▇▆▆▅▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>lr/pg2</td><td>▃▆███▇▇▆▆▅▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>metrics/mAP50(B)</td><td>▁▄▄█▇▇█▇████████████</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▁▂▃▇▇▇▇▆██▆▆▅▅▆▆▄▅▆█</td></tr><tr><td>metrics/precision(B)</td><td>▃▃▁▄▂▇▇▆▇█▇█▆█▆▇▇▇▇█</td></tr><tr><td>metrics/recall(B)</td><td>▁▃▃▂▂▄▇▆▇█▇█▇██▇██▇█</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>█▅▄▄▄▃▃▃▃▃▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train/cls_loss</td><td>█▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/dfl_loss</td><td>█▄▃▂▂▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val/box_loss</td><td>▇█▃▅▄▂▃▃▃▁▃▄▃▅▆▄▅▅▄▅</td></tr><tr><td>val/cls_loss</td><td>█▅▄▄▅▂▃▄▃▂▁▁▅▁▂▂▂▂▂▂</td></tr><tr><td>val/dfl_loss</td><td>█▇▄▅▄▂▃▄▂▁▃▃▄▅▅▄▄▄▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0001</td></tr><tr><td>lr/pg1</td><td>0.0001</td></tr><tr><td>lr/pg2</td><td>0.0001</td></tr><tr><td>metrics/mAP50(B)</td><td>0.98529</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.95465</td></tr><tr><td>metrics/precision(B)</td><td>0.96024</td></tr><tr><td>metrics/recall(B)</td><td>0.9672</td></tr><tr><td>model/GFLOPs</td><td>8.202</td></tr><tr><td>model/parameters</td><td>3012408</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>1.47</td></tr><tr><td>train/box_loss</td><td>0.13186</td></tr><tr><td>train/cls_loss</td><td>0.13097</td></tr><tr><td>train/dfl_loss</td><td>0.90782</td></tr><tr><td>val/box_loss</td><td>0.48603</td></tr><tr><td>val/cls_loss</td><td>1.68484</td></tr><tr><td>val/dfl_loss</td><td>1.04181</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">train</strong> at: <a href='https://wandb.ai/yustinachang/snooker_project/runs/g87o60wf' target=\"_blank\">https://wandb.ai/yustinachang/snooker_project/runs/g87o60wf</a><br/>Synced 6 W&B file(s), 24 media file(s), 5 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240408_234551-g87o60wf/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"metrics = model.val()  # no arguments needed, dataset and settings remembered\nmetrics.box.map    # map50-95\nmetrics.box.map50  # map50\nmetrics.box.map75  # map75\nmetrics.box.maps   # a list contains map50-95 of each category","metadata":{"execution":{"iopub.status.busy":"2024-04-09T00:24:00.383280Z","iopub.execute_input":"2024-04-09T00:24:00.383727Z","iopub.status.idle":"2024-04-09T00:24:23.780436Z","shell.execute_reply.started":"2024-04-09T00:24:00.383695Z","shell.execute_reply":"2024-04-09T00:24:23.779246Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.0.231 🚀 Python-3.10.12 torch-2.0.0+cpu CPU (Intel Xeon 2.20GHz)\nYOLOv8n summary (fused): 168 layers, 3007208 parameters, 0 gradients, 8.1 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolo_dataset/labels/val.cache... 2873 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2873/2873 [00:00<?, ?it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:15<00:00,  2.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2873       2873       0.96      0.967      0.985      0.955\n                 black       2873        359      0.974      0.932      0.981      0.971\n                  blue       2873        323      0.982          1       0.98      0.883\n                 brown       2873        331      0.876        0.9      0.972       0.96\n                 green       2873        239       0.98          1      0.995      0.993\n                  pink       2873         42      0.994          1      0.995      0.989\n                   red       2873        322      0.896      0.909      0.968      0.873\n                 white       2873       1233      0.997      0.997      0.995      0.972\n                yellow       2873         24      0.983          1      0.995      0.995\nSpeed: 0.0ms preprocess, 1.4ms inference, 0.0ms loss, 0.5ms postprocess per image\nResults saved to \u001b[1msnooker_project/train\u001b[0m\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array([    0.97129,     0.88341,     0.96002,     0.99271,     0.98944,     0.87298,     0.97235,       0.995])"},"metadata":{}}]},{"cell_type":"markdown","source":"### Model with **ONNX**","metadata":{"_kg_hide-input":false}},{"cell_type":"code","source":"model.export(format='onnx')","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-12-30T14:44:49.586404Z","iopub.status.idle":"2023-12-30T14:44:49.586886Z","shell.execute_reply.started":"2023-12-30T14:44:49.586659Z","shell.execute_reply":"2023-12-30T14:44:49.586680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ultralytics.utils.benchmarks import benchmark\nbenchmark(model='snooker_project/train/weights/best.pt', imgsz=128)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-12-30T14:44:49.588791Z","iopub.status.idle":"2023-12-30T14:44:49.589355Z","shell.execute_reply.started":"2023-12-30T14:44:49.589127Z","shell.execute_reply":"2023-12-30T14:44:49.589149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create a Download Link","metadata":{}},{"cell_type":"code","source":"%cd $OUTPUT_PATH\n!zip -r snooker_project.zip snooker_project\nfrom IPython.display import FileLink\nFileLink(r'snooker_project.zip')","metadata":{"execution":{"iopub.status.busy":"2024-04-09T00:24:23.782347Z","iopub.execute_input":"2024-04-09T00:24:23.782706Z","iopub.status.idle":"2024-04-09T00:24:26.046207Z","shell.execute_reply.started":"2024-04-09T00:24:23.782674Z","shell.execute_reply":"2024-04-09T00:24:26.045136Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/kaggle/working\n  adding: snooker_project/ (stored 0%)\n  adding: snooker_project/train/ (stored 0%)\n  adding: snooker_project/train/results.png (deflated 7%)\n  adding: snooker_project/train/PR_curve.png (deflated 16%)\n  adding: snooker_project/train/train_batch2.jpg (deflated 2%)\n  adding: snooker_project/train/labels.jpg (deflated 54%)\n  adding: snooker_project/train/val_batch1_labels.jpg (deflated 46%)\n  adding: snooker_project/train/args.yaml (deflated 52%)\n  adding: snooker_project/train/train_batch1802.jpg (deflated 4%)\n  adding: snooker_project/train/train_batch0.jpg (deflated 2%)\n  adding: snooker_project/train/weights/ (stored 0%)\n  adding: snooker_project/train/weights/last.pt (deflated 44%)\n  adding: snooker_project/train/weights/best.pt (deflated 44%)\n  adding: snooker_project/train/P_curve.png (deflated 6%)\n  adding: snooker_project/train/val_batch0_labels.jpg (deflated 29%)\n  adding: snooker_project/train/F1_curve.png (deflated 5%)\n  adding: snooker_project/train/train_batch1801.jpg (deflated 3%)\n  adding: snooker_project/train/val_batch2_pred.jpg (deflated 14%)\n  adding: snooker_project/train/val_batch0_pred.jpg (deflated 8%)\n  adding: snooker_project/train/train_batch1800.jpg (deflated 3%)\n  adding: snooker_project/train/R_curve.png (deflated 13%)\n  adding: snooker_project/train/confusion_matrix_normalized.png (deflated 22%)\n  adding: snooker_project/train/results.csv (deflated 83%)\n  adding: snooker_project/train/val_batch2_labels.jpg (deflated 36%)\n  adding: snooker_project/train/events.out.tfevents.1712619923.c69744afc264.42.0 (deflated 69%)\n  adding: snooker_project/train/val_batch1_pred.jpg (deflated 27%)\n  adding: snooker_project/train/labels_correlogram.jpg (deflated 73%)\n  adding: snooker_project/train/train_batch1.jpg (deflated 2%)\n  adding: snooker_project/train/confusion_matrix.png (deflated 23%)\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/snooker_project.zip","text/html":"<a href='snooker_project.zip' target='_blank'>snooker_project.zip</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Predict the Image","metadata":{}},{"cell_type":"code","source":"%cd $OUTPUT_PATH\nbest_model = YOLO(\"snooker_project/train/weights/best.pt\")\nbest_model.predict(source=image, show=False, save=True, name='image', exist_ok=True)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-30T17:05:46.470336Z","iopub.execute_input":"2023-12-30T17:05:46.470786Z","iopub.status.idle":"2023-12-30T17:05:47.952882Z","shell.execute_reply.started":"2023-12-30T17:05:46.470749Z","shell.execute_reply":"2023-12-30T17:05:47.951915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd $OUTPUT_PATH\nplt.imshow(cv2.cvtColor(cv2.imread('runs/detect/image/image1.jpg'), cv2.COLOR_BGR2RGB))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-30T17:05:59.547566Z","iopub.execute_input":"2023-12-30T17:05:59.548161Z","iopub.status.idle":"2023-12-30T17:05:59.867270Z","shell.execute_reply.started":"2023-12-30T17:05:59.548122Z","shell.execute_reply":"2023-12-30T17:05:59.865953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Video with PyTube","metadata":{}},{"cell_type":"code","source":"!pip install pytube\nfrom pytube import YouTube\nYouTube('https://youtu.be/hw02UKK4Kb0').streams.filter().get_highest_resolution().download(output_path=OUTPUT_PATH, filename='youtube.mp4')","metadata":{"execution":{"iopub.status.busy":"2023-12-30T14:44:49.600599Z","iopub.status.idle":"2023-12-30T14:44:49.601077Z","shell.execute_reply.started":"2023-12-30T14:44:49.600833Z","shell.execute_reply":"2023-12-30T14:44:49.600854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd $OUTPUT_PATH\n!ffmpeg -i youtube.mp4 -vcodec copy -acodec copy -ss 00:01:05 -to 00:01:15 video.mp4 -y","metadata":{"execution":{"iopub.status.busy":"2023-12-30T14:44:49.604060Z","iopub.status.idle":"2023-12-30T14:44:49.604532Z","shell.execute_reply.started":"2023-12-30T14:44:49.604312Z","shell.execute_reply":"2023-12-30T14:44:49.604335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict the Video","metadata":{}},{"cell_type":"code","source":"%cd $OUTPUT_PATH\nbest_model = YOLO(\"snooker_project/train/weights/best.pt\")\nbest_model.predict(source=video, show=False, save=True, name='predict', exist_ok=True)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-30T15:59:24.560169Z","iopub.execute_input":"2023-12-30T15:59:24.560594Z","iopub.status.idle":"2023-12-30T15:59:33.692673Z","shell.execute_reply.started":"2023-12-30T15:59:24.560561Z","shell.execute_reply":"2023-12-30T15:59:33.691375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd $OUTPUT_PATH\n!ffmpeg -y -loglevel panic -i runs/detect/predict/video.avi predict_video.mp4\nVideo(\"predict_video.mp4\", width=840)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T15:59:33.695342Z","iopub.execute_input":"2023-12-30T15:59:33.695972Z","iopub.status.idle":"2023-12-30T15:59:38.285101Z","shell.execute_reply.started":"2023-12-30T15:59:33.695921Z","shell.execute_reply":"2023-12-30T15:59:38.283423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict with **SAHI**","metadata":{}},{"cell_type":"code","source":"%cd $OUTPUT_PATH\n# Clone the ultralytics repository\n!git clone https://github.com/ultralytics/ultralytics.git ","metadata":{"execution":{"iopub.status.busy":"2024-04-09T00:36:27.124105Z","iopub.execute_input":"2024-04-09T00:36:27.124578Z","iopub.status.idle":"2024-04-09T00:36:28.263093Z","shell.execute_reply.started":"2024-04-09T00:36:27.124541Z","shell.execute_reply":"2024-04-09T00:36:28.261809Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"/kaggle/working\nfatal: destination path 'ultralytics' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U sahi","metadata":{"execution":{"iopub.status.busy":"2024-04-09T00:31:34.700616Z","iopub.execute_input":"2024-04-09T00:31:34.701110Z","iopub.status.idle":"2024-04-09T00:31:57.754395Z","shell.execute_reply.started":"2024-04-09T00:31:34.701069Z","shell.execute_reply":"2024-04-09T00:31:57.752575Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Collecting sahi\n  Obtaining dependency information for sahi from https://files.pythonhosted.org/packages/0b/da/23f351eb3360e58762f0d1ab2dc8521610cefb9e30e246eb715cbe337a38/sahi-0.11.15-py3-none-any.whl.metadata\n  Downloading sahi-0.11.15-py3-none-any.whl.metadata (15 kB)\nCollecting opencv-python<=4.8 (from sahi)\n  Obtaining dependency information for opencv-python<=4.8 from https://files.pythonhosted.org/packages/29/35/a791b550cdeb4efd8b66e921748f2aff938868a29794489d93575d604a02/opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nRequirement already satisfied: shapely>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from sahi) (1.8.5.post1)\nRequirement already satisfied: tqdm>=4.48.2 in /opt/conda/lib/python3.10/site-packages (from sahi) (4.66.1)\nRequirement already satisfied: pillow>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from sahi) (10.1.0)\nCollecting pybboxes==0.1.6 (from sahi)\n  Obtaining dependency information for pybboxes==0.1.6 from https://files.pythonhosted.org/packages/3c/3f/46f6613b41a3c2b4f7af3b526035771ca5bb12d6fdf3b23145899f785e36/pybboxes-0.1.6-py3-none-any.whl.metadata\n  Downloading pybboxes-0.1.6-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from sahi) (6.0.1)\nCollecting fire (from sahi)\n  Downloading fire-0.6.0.tar.gz (88 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting terminaltables (from sahi)\n  Obtaining dependency information for terminaltables from https://files.pythonhosted.org/packages/c4/fb/ea621e0a19733e01fe4005d46087d383693c0f4a8f824b47d8d4122c87e0/terminaltables-3.1.10-py2.py3-none-any.whl.metadata\n  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from sahi) (2.31.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sahi) (8.1.7)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pybboxes==0.1.6->sahi) (1.24.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire->sahi) (1.16.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire->sahi) (2.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->sahi) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->sahi) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->sahi) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->sahi) (2023.11.17)\nDownloading sahi-0.11.15-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pybboxes-0.1.6-py3-none-any.whl (24 kB)\nDownloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hDownloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\nBuilding wheels for collected packages: fire\n  Building wheel for fire (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117033 sha256=b8f086a44c8c69e2f39444386df12bcb8b62d27c4e375005dad7309a825696cf\n  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\nSuccessfully built fire\nInstalling collected packages: terminaltables, pybboxes, opencv-python, fire, sahi\n  Attempting uninstall: opencv-python\n    Found existing installation: opencv-python 4.8.1.78\n    Uninstalling opencv-python-4.8.1.78:\n      Successfully uninstalled opencv-python-4.8.1.78\nSuccessfully installed fire-0.6.0 opencv-python-4.7.0.72 pybboxes-0.1.6 sahi-0.11.15 terminaltables-3.1.10\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd $OUTPUT_PATH\n%cd ultralytics/examples/YOLOv8-SAHI-Inference-Video\n\n!python yolov8_sahi.py --source \"/kaggle/input/snooker-private-test/video.mp4\" --save-img --weights \"/kaggle/working/snooker_project/train/weights/best.pt\"","metadata":{"execution":{"iopub.status.busy":"2024-04-09T00:42:01.473546Z","iopub.execute_input":"2024-04-09T00:42:01.474052Z","iopub.status.idle":"2024-04-09T00:42:02.971797Z","shell.execute_reply.started":"2024-04-09T00:42:01.474012Z","shell.execute_reply":"2024-04-09T00:42:02.970213Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"/kaggle/working\n/kaggle/working/ultralytics/examples/YOLOv8-SAHI-Inference-Video\nTraceback (most recent call last):\n  File \"/kaggle/working/ultralytics/examples/YOLOv8-SAHI-Inference-Video/yolov8_sahi.py\", line 7, in <module>\n    from sahi import AutoDetectionModel\n  File \"/opt/conda/lib/python3.10/site-packages/sahi/__init__.py\", line 3, in <module>\n    from sahi.annotation import BoundingBox, Category, Mask\n  File \"/opt/conda/lib/python3.10/site-packages/sahi/annotation.py\", line 9, in <module>\n    from sahi.utils.coco import CocoAnnotation, CocoPrediction\n  File \"/opt/conda/lib/python3.10/site-packages/sahi/utils/coco.py\", line 17, in <module>\n    from shapely import MultiPolygon\nImportError: cannot import name 'MultiPolygon' from 'shapely' (/opt/conda/lib/python3.10/site-packages/shapely/__init__.py)\n","output_type":"stream"}]},{"cell_type":"code","source":"# from sahi.utils.yolov8 import download_yolov8s_model\n# from sahi import AutoDetectionModel\n# from sahi.utils.cv import read_image\n# from sahi.utils.file import download_from_url\nfrom sahi.predict import get_prediction, get_sliced_prediction, predict\n# from pathlib import Path","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_type = \"yolov8\"\nmodel_path = f\"{OUTPUT_PATH}/snooker_project/train/weights/best.pt\"\nmodel_device = \"cpu\" # or 'cuda:0'\nmodel_confidence_threshold = 0.4\n\nslice_height = 32\nslice_width = 32\noverlap_height_ratio = 0.2\noverlap_width_ratio = 0.2\n\nimage = '/kaggle/input/snooker-private-test/image1.jpg'\nvideo = '/kaggle/input/snooker-private-test/video.mp4'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd $OUTPUT_PATH\ndetection_model = AutoDetectionModel.from_pretrained(\n    model_type=model_type,\n    model_path=model_path,\n    device=model_device,\n    confidence_threshold=model_confidence_threshold,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = get_sliced_prediction(\n    image,\n    detection_model,\n    slice_height=slice_height,\n    slice_width=slice_width,\n    overlap_height_ratio=overlap_height_ratio,\n    overlap_width_ratio=overlap_width_ratio\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best_model.predict(source=video, show=False, save=True, name='predict', exist_ok=True)\npredict(\n    source=video, # \"path/to/dir\"\n    model_type=model_type,\n    model_path=model_path,\n    model_device=model_device,\n    model_confidence_threshold=model_confidence_threshold,\n    slice_height=slice_height,\n    slice_width=slice_width,\n    overlap_height_ratio=overlap_height_ratio,\n    overlap_width_ratio=overlap_width_ratio,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.export_visuals(export_dir=OUTPUT_PATH)\nImage(f\"{OUTPUT_PATH}/prediction_visual.png\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Track the Video with **ByteTrack**","metadata":{}},{"cell_type":"code","source":"%cd $OUTPUT_PATH\nbest_model = YOLO('snooker_project/train/weights/best.pt')\nbest_model.track(source=video, tracker=\"bytetrack.yaml\", save=True, name='track', exist_ok=True)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-30T14:44:49.617085Z","iopub.status.idle":"2023-12-30T14:44:49.617530Z","shell.execute_reply.started":"2023-12-30T14:44:49.617315Z","shell.execute_reply":"2023-12-30T14:44:49.617336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd $OUTPUT_PATH\n!ffmpeg -y -loglevel panic -i runs/detect/track/video.avi track_video.mp4\nVideo(\"track_video.mp4\", width=840)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T14:44:49.619008Z","iopub.status.idle":"2023-12-30T14:44:49.619434Z","shell.execute_reply.started":"2023-12-30T14:44:49.619227Z","shell.execute_reply":"2023-12-30T14:44:49.619246Z"},"trusted":true},"execution_count":null,"outputs":[]}]}